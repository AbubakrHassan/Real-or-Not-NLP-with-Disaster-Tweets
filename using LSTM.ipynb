{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import gensim\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim.scripts.glove2word2vec import glove2word2vec\n",
    "from gensim.test.utils import datapath, get_tmpfile\n",
    "import urllib\n",
    "np.random.seed(100)\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.layers import Dense, Activation, Flatten,Dropout,LSTM,Input,Embedding, Bidirectional\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.losses import mean_squared_error\n",
    "import keras.backend as K\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_file = datapath(\"/home/aims/Downloads/glove.twitter.27B/glove.twitter.27B.100d.txt\")\n",
    "tmp_file = get_tmpfile(\"glove_to_w2v.txt\")\n",
    "_ = glove2word2vec(glove_file, tmp_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KeyedVectors.load_word2vec_format(tmp_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aims/Documents/Git/Real-or-Not-NLP-with-Disaster-Tweets/venv/lib/python3.6/site-packages/ipykernel_launcher.py:2: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocabulary size=  1193514  words\n"
     ]
    }
   ],
   "source": [
    "wv = model\n",
    "words = list(wv.wv.vocab.keys())\n",
    "word_to_index, index_to_word = dict(),dict()\n",
    "for i,word in enumerate(words):\n",
    "    word_to_index[word]=i\n",
    "    index_to_word[i]=word\n",
    "print(\"vocabulary size= \",len(words),\" words\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorise(words,wv_model,max_length=35):\n",
    "    words = words.lower().split()\n",
    "    vectors = [wv_model[word] for word in words]\n",
    "    return append_zeros(vectors,max_length)\n",
    "def append_zeros(words,max_length):\n",
    "    for i in range(max_length-len(words)):\n",
    "        words.append(np.zeros(300))\n",
    "    return np.array(words)\n",
    "\n",
    "def sentences_to_indices(X, word_to_index, max_len):\n",
    "    m = X.shape[0]\n",
    "    X_indices = np.zeros((m, max_len),dtype=int)\n",
    "    for i in range(m):\n",
    "        sentence_words = X[i].split()\n",
    "        j = 0\n",
    "        for w in sentence_words:\n",
    "            if w in word_to_index:\n",
    "                X_indices[i, j] = word_to_index[w]\n",
    "            j = j+1\n",
    "            if j>=max_len:\n",
    "                break\n",
    "    return X_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(path,testing=False):\n",
    "    data = pd.read_csv(path)\n",
    "    \n",
    "    data[\"keyword\"].replace(np.nan,\"-\",inplace=True)\n",
    "    data[\"keyword\"] = data[\"keyword\"].apply(lambda x:urllib.parse.unquote(x))\n",
    "    \n",
    "    data[\"location\"].replace(np.nan,\"-\",inplace=True)\n",
    "    data[\"location\"] = data[\"location\"].apply(lambda x: re.sub(\"[^-a-zA-Z\\s]\",\"\",x))\n",
    "    \n",
    "    data[\"text\"] = data[\"text\"].apply(lambda x: re.sub(\"[^\\w\\s#'_]\",\"\",x)).apply(lambda x:x.lower())\n",
    "    data[\"text\"] = data[\"text\"].apply(lambda x: \" \".join([a for a in re.split(\"([#$])\",x) if len(a)!=0]))\n",
    "    \n",
    "    \n",
    "    new_data = pd.DataFrame()\n",
    "    new_data[\"id\"] = data[\"id\"]\n",
    "    \n",
    "    new_data[\"text\"] = data[\"keyword\"] + \" \" + data[\"location\"]+ \" \" + data[\"text\"]\n",
    "    \n",
    "    \n",
    "    if not testing:\n",
    "        new_data[\"target\"] = data[\"target\"]\n",
    "    return new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LENGTH = 35\n",
    "\n",
    "def pretrained_embedding_layer(word_to_vec_map, word_to_index):\n",
    "    vocab_len = len(word_to_index) + 1\n",
    "    emb_dim = word_to_vec_map[\"hello\"].shape[0]\n",
    "    emb_matrix = np.zeros((vocab_len,emb_dim))\n",
    "                                            \n",
    "    for word, index in word_to_index.items():\n",
    "        emb_matrix[index, :] = word_to_vec_map[word]\n",
    "        \n",
    "    embedding_layer = Embedding(vocab_len, emb_dim, trainable = False)\n",
    "    embedding_layer.build((None,))\n",
    "    embedding_layer.set_weights([emb_matrix])\n",
    "    return embedding_layer\n",
    "\n",
    "def deepLSTM(input_shape, dropout_prob,n_h):\n",
    "    input_data = Input(shape=input_shape)\n",
    "    embedding_layer = pretrained_embedding_layer(wv,word_to_index)(input_data)\n",
    "    X = Bidirectional(LSTM(n_h ,return_sequences=True))(embedding_layer)\n",
    "    X = Dropout(dropout_prob)(X)\n",
    "    X = Bidirectional(LSTM(n_h ,return_sequences=False))(X)\n",
    "    X = Dropout(dropout_prob)(X)\n",
    "    X = Dense(128)(X)\n",
    "    X = Activation(\"sigmoid\")(X)\n",
    "    X = Dense(1)(X)\n",
    "    X = Activation(\"sigmoid\")(X)\n",
    "           \n",
    "    model = Model(inputs=input_data, outputs=X)\n",
    "    return model\n",
    "model = deepLSTM((MAX_LENGTH,), 0.5, 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>- - our deeds are the reason of this  # earthq...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>- - forest fire near la ronge sask canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>- - all residents asked to 'shelter in place' ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>- - 13000 people receive  # wildfires evacuati...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>- - just got sent this photo from ruby  # alas...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                               text  target\n",
       "0   1  - - our deeds are the reason of this  # earthq...       1\n",
       "1   4          - - forest fire near la ronge sask canada       1\n",
       "2   5  - - all residents asked to 'shelter in place' ...       1\n",
       "3   6  - - 13000 people receive  # wildfires evacuati...       1\n",
       "4   7  - - just got sent this photo from ruby  # alas...       1"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_path = \"./data/train.csv\"\n",
    "train_data = read_data(train_path)\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(train_data[\"text\"], train_data[\"target\"], test_size=0.33, random_state=42)\n",
    "X_train = sentences_to_indices(np.array(X_train.values),word_to_index,MAX_LENGTH)\n",
    "X_test = sentences_to_indices(np.array(X_test.values),word_to_index,MAX_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 90375,      0,      0, ...,      0,      0,      0],\n",
       "       [    28,     28,     13, ...,      0,      0,      0],\n",
       "       [  1851,     28,    246, ...,      0,      0,      0],\n",
       "       ...,\n",
       "       [  2705,     28, 276515, ...,      0,      0,      0],\n",
       "       [    28,     28,  15112, ...,      0,      0,      0],\n",
       "       [134094,      0,      0, ...,      0,      0,      0]])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_9 (InputLayer)         (None, 35)                0         \n",
      "_________________________________________________________________\n",
      "embedding_9 (Embedding)      (None, 35, 100)           119351500 \n",
      "_________________________________________________________________\n",
      "bidirectional_5 (Bidirection (None, 35, 256)           234496    \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 35, 256)           0         \n",
      "_________________________________________________________________\n",
      "bidirectional_6 (Bidirection (None, 256)               394240    \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 1)                 129       \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 120,013,261\n",
      "Trainable params: 661,761\n",
      "Non-trainable params: 119,351,500\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss=mean_squared_error,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [EarlyStopping(monitor='val_loss', patience=10),ModelCheckpoint(\"best_model.h5\",monitor=\"val_loss\",mode=\"min\",save_best_only=True,verbose=True)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5100 samples, validate on 2513 samples\n",
      "Epoch 1/100\n",
      "5100/5100 [==============================] - 16s 3ms/step - loss: 0.1676 - accuracy: 0.7588 - val_loss: 0.1962 - val_accuracy: 0.7222\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.19620, saving model to best_model.h5\n",
      "Epoch 2/100\n",
      "5100/5100 [==============================] - 15s 3ms/step - loss: 0.1411 - accuracy: 0.8039 - val_loss: 0.1418 - val_accuracy: 0.8074\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.19620 to 0.14183, saving model to best_model.h5\n",
      "Epoch 3/100\n",
      "5100/5100 [==============================] - 15s 3ms/step - loss: 0.1365 - accuracy: 0.8125 - val_loss: 0.1347 - val_accuracy: 0.8138\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.14183 to 0.13466, saving model to best_model.h5\n",
      "Epoch 4/100\n",
      "5100/5100 [==============================] - 14s 3ms/step - loss: 0.1286 - accuracy: 0.8251 - val_loss: 0.1358 - val_accuracy: 0.8150\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.13466\n",
      "Epoch 5/100\n",
      "5100/5100 [==============================] - 15s 3ms/step - loss: 0.1238 - accuracy: 0.8306 - val_loss: 0.1387 - val_accuracy: 0.8070\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.13466\n",
      "Epoch 6/100\n",
      "5100/5100 [==============================] - 15s 3ms/step - loss: 0.1232 - accuracy: 0.8373 - val_loss: 0.1487 - val_accuracy: 0.7907\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.13466\n",
      "Epoch 7/100\n",
      "5100/5100 [==============================] - 17s 3ms/step - loss: 0.1145 - accuracy: 0.8482 - val_loss: 0.1564 - val_accuracy: 0.7899\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.13466\n",
      "Epoch 8/100\n",
      "5100/5100 [==============================] - 16s 3ms/step - loss: 0.1096 - accuracy: 0.8565 - val_loss: 0.1317 - val_accuracy: 0.8205\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.13466 to 0.13174, saving model to best_model.h5\n",
      "Epoch 9/100\n",
      "5100/5100 [==============================] - 15s 3ms/step - loss: 0.1033 - accuracy: 0.8667 - val_loss: 0.1445 - val_accuracy: 0.8082\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.13174\n",
      "Epoch 10/100\n",
      "5100/5100 [==============================] - 17s 3ms/step - loss: 0.0975 - accuracy: 0.8725 - val_loss: 0.1458 - val_accuracy: 0.8170\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.13174\n",
      "Epoch 11/100\n",
      "5100/5100 [==============================] - 16s 3ms/step - loss: 0.0912 - accuracy: 0.8837 - val_loss: 0.1420 - val_accuracy: 0.8170\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.13174\n",
      "Epoch 12/100\n",
      "5100/5100 [==============================] - 15s 3ms/step - loss: 0.0837 - accuracy: 0.8982 - val_loss: 0.1466 - val_accuracy: 0.8150\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.13174\n",
      "Epoch 13/100\n",
      "5100/5100 [==============================] - 14s 3ms/step - loss: 0.0789 - accuracy: 0.9031 - val_loss: 0.1505 - val_accuracy: 0.8146\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.13174\n",
      "Epoch 14/100\n",
      "5100/5100 [==============================] - 15s 3ms/step - loss: 0.0767 - accuracy: 0.9039 - val_loss: 0.1568 - val_accuracy: 0.8054\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.13174\n",
      "Epoch 15/100\n",
      "5100/5100 [==============================] - 15s 3ms/step - loss: 0.0667 - accuracy: 0.9186 - val_loss: 0.1595 - val_accuracy: 0.8018\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.13174\n",
      "Epoch 16/100\n",
      "5100/5100 [==============================] - 15s 3ms/step - loss: 0.0643 - accuracy: 0.9227 - val_loss: 0.1759 - val_accuracy: 0.7835\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.13174\n",
      "Epoch 17/100\n",
      "5100/5100 [==============================] - 15s 3ms/step - loss: 0.0607 - accuracy: 0.9282 - val_loss: 0.1609 - val_accuracy: 0.8070\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.13174\n",
      "Epoch 18/100\n",
      "5100/5100 [==============================] - 14s 3ms/step - loss: 0.0574 - accuracy: 0.9322 - val_loss: 0.1680 - val_accuracy: 0.7990\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.13174\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7fc7c629ff60>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=100, batch_size=32,validation_data=(X_test, y_test),shuffle=True,callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.820533227218464"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = load_model(\"./best_model.h5\")\n",
    "np.mean(model.predict(X_test).round().reshape(-1)==y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_data = read_data(\"./data/test.csv\",testing=True)\n",
    "X_test = sentences_to_indices(test_data[\"text\"].values,word_to_index, MAX_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  28,   28,   59, ...,    0,    0,    0],\n",
       "       [  28,   28, 1220, ...,    0,    0,    0],\n",
       "       [  28,   28,  175, ...,    0,    0,    0],\n",
       "       ...,\n",
       "       [  28,   28, 1745, ...,    0,    0,    0],\n",
       "       [  28,   28, 9040, ...,    0,    0,    0],\n",
       "       [  28,   28,  506, ...,    0,    0,    0]])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = model.predict(X_test).round().reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_res = pd.DataFrame()\n",
    "test_res[\"id\"]= test_data[\"id\"]\n",
    "test_res[\"target\"] = res.astype(np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_res.to_csv(r\"./result/res_lstm_single_layer.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kaggle-real-or-not-venv",
   "language": "python",
   "name": "kaggle-real-or-not-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
